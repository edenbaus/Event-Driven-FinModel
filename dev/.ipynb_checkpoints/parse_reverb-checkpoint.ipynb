{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named textblob",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f8a4027e976a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named textblob"
     ]
    }
   ],
   "source": [
    "### this file is used to add sentiment polarity in existing dataframe\n",
    "### input: pandas dataframe with date, news title, news content \n",
    "\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import sys  \n",
    "import datetime as dt\n",
    "from dateutil.parser import parse\n",
    "reload(sys)  \n",
    "sys.setdefaultencoding('utf8')\n",
    "def senti():\n",
    "\tticker, data=parse_1()\n",
    "\tPolarity = map(lambda x: TextBlob(x),data.content)\n",
    "\tresult=[]\n",
    "\tfor i in range(len(Polarity)):\n",
    "\t\tk = Polarity[i].sentiment.polarity\n",
    "\t\tresult.append(k)\n",
    "\tdata['polarity']=result\n",
    "\tdf=date_transform(data)\n",
    "\t####################transform data to standard structure###############\n",
    "\treturn ticker,data\n",
    "\n",
    "def parse_1():\n",
    "\tTicker=raw_input('please input ticker: ')\n",
    "\tdata=open('../data/'+Ticker+'.csv')\n",
    "\tarray=data.read().split('|')\n",
    "\tdate=[]\n",
    "\tcontent=[]\n",
    "\tfor i in range(2,len(array)-1):\n",
    "\t\tif len(array[i])<30:\n",
    "\t\t\tdate.append(array[i])\n",
    "\t\telse:\n",
    "\t\t\tcontent.append(array[i])\n",
    "\tdic={}\n",
    "\tdic['date']=date\n",
    "\tdic['content']=content\n",
    "\tdf=pd.DataFrame(dic)\n",
    "\treturn Ticker,df\n",
    "\n",
    "def date_transform(df):\n",
    "\tdate=df.date\n",
    "\ty=range(2007,2017)\n",
    "\tyear=map(lambda x: str(x), y)\n",
    "\n",
    "\t\n",
    "\treal_date=[]\n",
    "\tfor i in range(len(date)):\n",
    "\t\tif any(word in date[i] for word in year):\n",
    "\t\t\td=date[i].split(',')[0]+date[i].split(',')[1]\n",
    "\t\t\tdat=parse(d).strftime('%-m/%-d/%y')\n",
    "\t\t####has year#####\n",
    "\t\t\treal_date.append(dat)\n",
    "\t\telse:\n",
    "\t\t\td=date[i].split(',')[1]+' 2017'\n",
    "\t\t\tdat=parse(d).strftime('%-m/%-d/%y')\n",
    "\t\t\treal_date.append(dat)\n",
    "\tj=0\n",
    "\twhile ':' in real_date[j]:\n",
    "\t\tj=j+1\n",
    "\tdf.date=real_date\n",
    "\tdf=df.iloc[j:,:]\n",
    "\treturn df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ticker=\"BAC\"\n",
    "market_data=pd.read_csv('../data/Price/'+ticker+'.csv',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_1(Ticker):\n",
    "\tdata=open('../data/'+Ticker+'.csv')\n",
    "\tarray=data.read().split('|')\n",
    "\tdate=[]\n",
    "\tcontent=[]\n",
    "\tfor i in range(2,len(array)-1):\n",
    "\t\tif len(array[i])<30:\n",
    "\t\t\tdate.append(array[i])\n",
    "\t\telse:\n",
    "\t\t\tcontent.append(array[i])\n",
    "\tdic={}\n",
    "\tdic['date']=date\n",
    "\tdic['content']=content\n",
    "\tdf=pd.DataFrame(dic)\n",
    "\treturn Ticker,df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ticker,df=parse_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "def date_transform(df):\n",
    "\tdate=df.date\n",
    "\ty=range(2007,2017)\n",
    "\tyear=map(lambda x: str(x), y)\n",
    "\n",
    "\t\n",
    "\treal_date=[]\n",
    "\tfor i in range(len(date)):\n",
    "\t\tif any(word in date[i] for word in year):\n",
    "\t\t\td=date[i].split(',')[0]+date[i].split(',')[1]\n",
    "\t\t\tdat=parse(d).strftime('%-m/%-d/%y')\n",
    "\t\t####has year#####\n",
    "\t\t\treal_date.append(dat)\n",
    "\t\telse:\n",
    "\t\t\td=date[i].split(',')[1]+' 2017'\n",
    "\t\t\tdat=parse(d).strftime('%-m/%-d/%y')\n",
    "\t\t\treal_date.append(dat)\n",
    "\tj=0\n",
    "\twhile ':' in real_date[j]:\n",
    "\t\tj=j+1\n",
    "\tdf.date=real_date\n",
    "\tdf=df.iloc[j:,:]\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=date_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=market_data.merge(df,how='left',left_on='Date',right_on='date').drop('date',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "return_=[]\n",
    "for i in range(market_data.shape[0]-1):\n",
    "    return_.append(market_data.iloc[i+1,1]/market_data.iloc[i,1]-1.0)\n",
    "date=market_data.Date[1:]\n",
    "df={}\n",
    "return_5=return_[:-5]\n",
    "return_4=return_[1:-4]\n",
    "return_3=return_[2:-3]\n",
    "return_2=return_[3:-2]\n",
    "return_1=return_[4:-1]\n",
    "return_y=return_[5:]\n",
    "df['return_5']=return_5\n",
    "df['return_4']=return_4\n",
    "df['return_3']=return_3\n",
    "df['return_2']=return_2\n",
    "df['return_1']=return_1\n",
    "df['return_y']=map(lambda x: 1 if x>=0 else 0,return_y)\n",
    "df['Date']=date[5:]\n",
    "dataframe=pd.DataFrame(df)\n",
    "common_data=pd.read_csv('../data/Price/common_data.csv',header=0)\n",
    "final=dataframe.merge(common_data,how='left',on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TickerList=[\"AA\",\"AAPL\",\"ABT\",\"AMAT\",\"BAC\",\"BBBY\",\"C\",\"CAT\",\"CHK\",\"D\",\"DOW\",\"F\",\"FCX\",\"GE\",\"JNJ\",\"JNPR\",\"K\",\\\n",
    "            \"KO\",\"LLY\",\"LMT\",\"MCD\",\"PG\",\"PPL\",\"RF\",\"SLB\",\"SO\",\"T\",\"VOD\",\"VZ\",\"XOM\"]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ticker,df=parse_1(\"AA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A=list(df.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A.append(list(parse_1(\"AAPL\")[1].content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('../data/reverb/AAreverb.csv',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = [['first#', '','fdsab','sentence'], ['second', 'sentence']]\n",
    "model = Word2Vec(sentences, min_count=1,size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A=data.loc[:,['subject','object','verb']].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'attribute to'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.iloc[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainset(df):\n",
    "    all_sentence=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        sentence=[]\n",
    "        for j in range(df.shape[1]):\n",
    "            string=str(df.iloc[i,j])\n",
    "            if len(string)!=0:\n",
    "                sentence+=string.split(' ')\n",
    "        all_sentence.append(sentence)\n",
    "    return all_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set=trainset(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(train_set, min_count=1,size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AllLis=[]\n",
    "for each in train_set:\n",
    "    lis=[0]*100\n",
    "    if len(each)!=0:\n",
    "        for each_word in each:\n",
    "            lis+=model.wv[each_word]\n",
    "        lis/=len(each)\n",
    "    AllLis.append(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
